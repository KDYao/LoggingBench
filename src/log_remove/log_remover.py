"""
This script removes logging statements form java projects
"""
import src.util.utils as ut
import os
import json
import random
import pandas as pd
from collections import defaultdict

class LogRemover:
    def __init__(self, sample_dir='../../result/proj_sample', f_log_stats='../../conf/log_all_stats.csv',
                 repeats=1):
        self.sample_dir = sample_dir
        if not os.path.isdir(sample_dir):
            os.makedirs(sample_dir)
        self.sample_sizes = ['small', 'medium', 'large', 'vlarge']
        self.repeats = repeats
        self.lu_levels = self.load_lu_levels()
        self.df_proj_lus = self.load_lu_per_project(f_log_stats)
        # Generate sampled projects from each size
        self.project_sample()

    def load_lu_per_project(self, f):
        """
        Load log_all_stats.csv and get the LUs used in each project
        This file currently is not being tracked since its generated by Chen not us
        We do not wish to disclose too much details before we have Chen's permission
        Parameters
        ----------
        f

        Returns
        -------

        """
        df = ut.csv_loader(f)
        df['project_id'] = df['project'].apply(lambda x: int(x.split('-')[0]))
        keep_cols = ['project_id', 'others'] + [x for x in self.lu_levels.keys() if x in df.columns]
        return df[keep_cols]


    def load_lu_levels(self, f='../../conf/lu_levels.json'):
        """
        Load logging utilities
        Parameters
        ----------
        f
        extra

        Returns
        -------

        """
        with open(f) as r:
         lu_levels = json.load(r)
        return lu_levels

    def filter_row(self, row):
        """
        Check if a row contain general logging utilities
        If listed LU is not in recorded dataset as a separate column, will check it through the 'others' column
        Parameters
        ----------
        row
        cols

        Returns
        If is general LU, and the LU used
        -------

        """
        general_lus = []
        for x in self.lu_levels.keys():
            if x in row.keys():
                ig = row[x]
            else:
                if isinstance(row['others'], str):
                    ig = (x in row['others'])
                else:
                    continue
            if ig is True:
                general_lus.append(x)
        return len(general_lus) > 0, general_lus


    def filter_projects_by_lus(self, df):
        """
        Filter projects by selected logging utilities
        Returns
        -------
        """
        df = pd.merge(df, self.df_proj_lus, on='project_id')
        df[['is_general', 'general_lus']] = df.apply(func=self.filter_row, axis=1, result_type='expand')
        return df[df['is_general'] == True]



    def project_sample(self, sample_percentage=0.1, overwrite=False):
        """
        Sample 10% of the projects from each size
        Parameters
        ----------
        sample_percentage: The percentage of sampling
        overwrite: if overwrite existing files

        Returns
        -------

        """
        sloc_dir = '../../result/proj_sloc'
        ut.print_msg_box('Sample {}% projects from each size'.format(sample_percentage * 100))
        # Concatenate all size types to be analyzed
        for repeat in range(1, self.repeats + 1):
            for size_type in self.sample_sizes:
                f_projects_sample = os.path.join(self.sample_dir, 'sample_{}_sloc_{}.csv'.format(repeat, size_type))
                if os.path.isfile(f_projects_sample):
                    if overwrite:
                        print('Overwrite existing project {}'.format(os.path.basename(f_projects_sample)))
                    else:
                        print('Sample projects already exist in {}; skip'.format(os.path.basename(f_projects_sample)))
                        continue
                df_projects = ut.csv_loader(os.path.join(sloc_dir, 'filesize_sloc_{}.csv'.format(size_type)))
                df_projects = self.filter_projects_by_lus(df=df_projects)
                df_projects_sample = df_projects.sample(frac=sample_percentage, random_state=repeat)
                df_projects_sample.to_csv(f_projects_sample, index=False)

    def logger_detector(self):
        """
        Detect java files with logging statements such as logger, etc. followed by a function call.
        Returns
        -------
        """


if __name__ == '__main__':
    logremover = LogRemover()
